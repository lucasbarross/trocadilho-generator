{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "##  Trocadilho Generator \n",
        "\n",
        "Notebook modified from the original by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read this [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use the original notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_"
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1f2b28-69fe-47a2-b933-5c9f104bc4db"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  2 20:01:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de94ebfc-b1d9-4e21-c025-67a263e82578"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 409Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 7.32Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 740Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:10, 47.6Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 524Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 10.1Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 12.2Mit/s]                                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d220c773-acff-4743-cc7a-894c29bfe12d"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Downloading a Text File to be Trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/lucasbarross/trocadilho-generator/main/training/jokes.txt\"\n",
        "data = requests.get(url)\n",
        "file_name = \"jokes.txt\"\n",
        "\n",
        "with open(file_name, 'w') as f:\n",
        "  f.write(data.text)\n",
        "\n",
        "gpt2.copy_file_from_gdrive(\"../../\"+file_name)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Training the Model\n",
        "\n",
        "The next cell will start the actual finetuning/training of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b51720-5b5a-4738-e09c-fda8fdf16066"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1470.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 13288 tokens\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 | 48.76] loss=3.82 avg=3.82\n",
            "[20 | 92.44] loss=3.32 avg=3.57\n",
            "[30 | 136.07] loss=2.74 avg=3.29\n",
            "[40 | 179.70] loss=2.21 avg=3.02\n",
            "[50 | 223.27] loss=1.37 avg=2.68\n",
            "[60 | 266.82] loss=0.92 avg=2.38\n",
            "[70 | 310.33] loss=0.50 avg=2.10\n",
            "[80 | 353.74] loss=0.31 avg=1.87\n",
            "[90 | 397.21] loss=0.28 avg=1.69\n",
            "[100 | 440.79] loss=0.11 avg=1.52\n",
            "[110 | 484.29] loss=0.08 avg=1.38\n",
            "[120 | 527.83] loss=0.07 avg=1.27\n",
            "[130 | 571.35] loss=0.06 avg=1.17\n",
            "[140 | 614.88] loss=0.04 avg=1.08\n",
            "[150 | 658.39] loss=0.15 avg=1.02\n",
            "[160 | 701.92] loss=0.04 avg=0.95\n",
            "[170 | 745.46] loss=0.04 avg=0.89\n",
            "[180 | 789.01] loss=0.04 avg=0.84\n",
            "[190 | 832.53] loss=0.03 avg=0.79\n",
            "[200 | 876.09] loss=0.04 avg=0.75\n",
            "======== SAMPLE 1 ========\n",
            "nou para as subiu em 1? As subiu-izé.\n",
            "Qual é a fruta que é o super-herói do super-herói do super-smaragda? O Li Mão.\n",
            "Qual é o frango que as outras povas fugroneira? Os ma-feios.\n",
            "Qual é o jogador que as atores vovôs estás? O jogador-dos.\n",
            "Por que  o filho do filho? Porque ele é filho-doke.\n",
            "Por que o surfista não é líquido? Porque não é líquido\n",
            "Qual é o fenômeno que acontece no mar que o Thor tem medo? Thorniquete.\n",
            "Qual o animal que mais gosta de jogar futebol? O goooooooooolfinho.\n",
            "Tinha um pontinho verde no Xbox, qual é o nome do jogo? Assassins GreenD.\n",
            "Por que  o banheiro não é considerado um carro? Porque ele era um jogo de tolerado.\n",
            "Por que a vaca foi pra Alemanha? Porque era po-piê.\n",
            "Por que o magel voade o irmãe açaí disse para a cabeça que se chama você tem o outro. Você sabe vão à tão de calor.\n",
            "Qual é o o celular que o eletrodoméstico da seleção brasileira de passatos? Celular.\n",
            "Qual é o oomma corpo do oceano? Opta.\n",
            "Qual o anedatics que anda mundo de tolerado. Comque no escrever mais depressa sem aponta onde as pessoas estão? Aponta-demandas.\n",
            "Por que a loira joga o relógio pela janela? Porque ela é morre a Holanda.\n",
            "O que é que é é é que depois de ficar com os cartas mais depressaendas? Comer têm o Peter Cheque.\n",
            "Por que é que o depressa é precipitada pela janela? Porque ele é precipitada elétrica.\n",
            "Qual é a parte do quarto que o Thor mais gosta de contar? Thor-istóscnício.\n",
            "Tinha um salo de um ofícia com se chama Chá-seis isola. Qual o nome do desenho todo quarto? Sonja-ingredinho.\n",
            "Qual é o desenho todos los saudades? Ah, Dien 👜‍♯️.\n",
            "Qual o alimento de entregard todos los gostam? And so on...\n",
            "O que é que se adapta decem cima no espaço? O que é que quando bêbado o seuugu empolar?\n",
            "Qual é o país onde as pessoas mais praticam musculação? Só-malha.\n",
            "Por que o vaso é considerado um ver Muuuuu-nique? Porque é dezão só prescrever.\n",
            "Por que o vaso é considerado um sao-cho? Porque ele é dezão só um sao-dia.\n",
            "Qual é o pão que o Batman é considerado um cachorro? Bat-deia.\n",
            "Qual é o animal que mais as pessoas mais praticam? Ame-pai.\n",
            "Qual animal é a capital que beija todo mundo? Mendoça.\n",
            "Qual é o order que sempre absolur quem é o nome do koch ― é o lugar de dois dá pra se favorita de cada vez? Muuuuuuuuuuu-a.\n",
            "Qual animal é o nome da norma jurídica ― é o nome da feminógrafo não relógio é para ser um peixe? Laba-fe-cáve.\n",
            "Qual é a capital entre o órgão mais entende? Uau-fe-cáve.\n",
            "Qual é a comida que tem problema, e o tom-de-les? En-Churo.\n",
            "Por que nos montes mais altos e frios da Suíça tem cachorros? Porque lá estão os au-aupes.\n",
            "Qual é o frango que é o idoso quando está na rua? O brinquedo\n",
            "\n",
            "[210 | 939.92] loss=0.03 avg=0.72\n",
            "[220 | 983.45] loss=0.03 avg=0.68\n",
            "[230 | 1027.04] loss=0.02 avg=0.65\n",
            "[240 | 1070.61] loss=0.03 avg=0.62\n",
            "[250 | 1114.14] loss=0.03 avg=0.59\n",
            "[260 | 1157.61] loss=0.05 avg=0.57\n",
            "[270 | 1201.16] loss=0.04 avg=0.55\n",
            "[280 | 1244.69] loss=0.02 avg=0.53\n",
            "[290 | 1288.27] loss=0.02 avg=0.51\n",
            "[300 | 1331.82] loss=0.03 avg=0.49\n",
            "[310 | 1375.37] loss=0.03 avg=0.47\n",
            "[320 | 1418.88] loss=0.06 avg=0.46\n",
            "[330 | 1462.33] loss=0.03 avg=0.44\n",
            "[340 | 1505.76] loss=0.02 avg=0.43\n",
            "[350 | 1549.20] loss=0.03 avg=0.41\n",
            "[360 | 1592.63] loss=0.02 avg=0.40\n",
            "[370 | 1636.05] loss=0.03 avg=0.39\n",
            "[380 | 1679.48] loss=0.02 avg=0.38\n",
            "[390 | 1722.90] loss=0.02 avg=0.36\n",
            "[400 | 1766.33] loss=0.02 avg=0.35\n",
            "======== SAMPLE 1 ========\n",
            " au carro, volta e garai a bem tênis? Porque mora no Brasil parro je nei quando se esque.\n",
            "Qual a se-cores que os viciados em qualquer pront the galaxão? Gisele Print.\n",
            "Qual a dos maquilos de tomá pra fazer? Gisele Albeiro.\n",
            "Qual a comida que tem um cachorro-quente? A clique.\n",
            "Por que a rua au Sarmiento tem não pote em pó se declara? Porque ela é um cachorro-quente.\n",
            "Qual o veículo de comunicação que sempre estavam em ace enrijecida? Jabuti-Cabra.\n",
            "Por que um homem vivia cheio de velas em sua casa? Porque ele queria achar o tesouro.\n",
            "Qual a fruta que termina primeiro do ferreiro? O golfer-a.\n",
            "Por que a monkia habo a cama do porque ela ditaba? Porque ele punho a vaca.\n",
            "Qual é a explosão do Thor? O médicoThor.\n",
            "O que o zero é que o médico febou delauno e o outro.\n",
            "Qual o carro que fazer interfixa? Cooper.\n",
            "Por que a vaca foi pra Alemanha? Porque ele queria achar o tesouro.\n",
            "Qual o as senhor do Thor? FoTHormode.\n",
            "Qual a haste de metal que diz estavam com picolés? Dynamite.\n",
            "Qual a haste de metal juntar um pontinho delas? Rodrigo Faro.\n",
            "Qual é o traficante que mais gosta de flores? Cast-a-Coca.\n",
            "Qual é a parte mais feminina da casa? JanELA.\n",
            "Por que o cachorro o seu cachorro-pode? Porque ele queria astrônomo desencapado.\n",
            "Qual o contrário de cachorro-pens? Porque ele era dia de cheia.\n",
            "Represento o amor, mas amor não posso ter, me desenh ofto e um cavalheiro, mais amado muskota que no interior o também é do as chapéiros.\n",
            "O que o zero dise para o meusquier 1 que o zero estudiante 2? Agulha.\n",
            "O que passa o próximais que se o rico comer ele morre? Agulha.\n",
            "O que o carro estava no trêsse? Engata.\n",
            "Por que o cachorro ia communo não gosta da casa? Porque ela é engata fecha a novela.\n",
            "Por que no barco de futebol não quem é empatado estava o demais? Porque elas é empatado um clipe.\n",
            "Qual o veículo que lava roupas? Tanque.\n",
            "Qual é a diferença entre a cachaça e a mulher? A cachaça dá dor de cabeça só um dia.\n",
            "Por que o macaco tem medo de martelo? Porque ele é um macaco-prego.\n",
            "Por que o jogador não estava conseguindo ligar do campo? Porque ele estava fora de cachorro.\n",
            "Qual o veículo que o Médico mais preguiçoso que tem no TV? Muuuuriçoca.\n",
            "Por que o jogador não estava acabou carnive? Porque ele estava coronirão.\n",
            "Qual é o hidrocarboneto da raiva? Hadao filho.\n",
            "Qual é a vaca que molhar tra outra? Da Thornea.\n",
            "Por que o maior dramaturgo de língua inglesa? Porque ela é língua a mãe açaí.\n",
            "Qual o contrário de papelada? Porque ele quer que tá sempre chie.\n",
            "Não perdido de bacon é o brinquedo? É o brinquedo de volta a-dá.\n",
            "Qual o time mais amado da gama de cantar? Caetano De Caesarean.\n",
            "Qual a ave que are causez-am mas? Fazem-Zé.\n",
            "Por\n",
            "\n",
            "[410 | 1828.47] loss=0.02 avg=0.34\n",
            "[420 | 1871.98] loss=0.02 avg=0.34\n",
            "[430 | 1915.46] loss=0.03 avg=0.33\n",
            "[440 | 1958.91] loss=0.02 avg=0.32\n",
            "[450 | 2002.34] loss=0.02 avg=0.31\n",
            "[460 | 2045.81] loss=0.02 avg=0.30\n",
            "[470 | 2089.29] loss=0.02 avg=0.29\n",
            "[480 | 2132.77] loss=0.02 avg=0.29\n",
            "[490 | 2176.21] loss=0.02 avg=0.28\n",
            "[500 | 2219.72] loss=0.02 avg=0.27\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 2266.09] loss=0.02 avg=0.27\n",
            "[520 | 2309.55] loss=0.03 avg=0.26\n",
            "[530 | 2352.98] loss=0.02 avg=0.26\n",
            "[540 | 2396.40] loss=0.02 avg=0.25\n",
            "[550 | 2439.84] loss=0.02 avg=0.24\n",
            "[560 | 2483.31] loss=0.02 avg=0.24\n",
            "[570 | 2526.76] loss=0.02 avg=0.23\n",
            "[580 | 2570.24] loss=0.02 avg=0.23\n",
            "[590 | 2613.70] loss=0.02 avg=0.22\n",
            "[600 | 2657.15] loss=0.02 avg=0.22\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "Thor: Ragnarok\n",
            "O que o zero disse para o só futebol? Nossa.\n",
            "Qual é o aparelho pelo que trabalha com montaria? Carro-o-leito.\n",
            "Qual é o pato que correce de futebol so far as regards audio? Corre-sca.\n",
            "Qual é o animal que mais gosta de flores? A fo-foca.\n",
            "Por que o folhada estava quando acordasse fizesse? Porque lá fase buzinou.\n",
            "Qual é o apósio afficionado que tem tudo? Tony Ramos.\n",
            "Qual é a especialização do Mundo? Para fazer.\n",
            "O que o zero dise para o oito? Nossa.\n",
            "Qual a cantora que mais gosta de flores? Ama-gadinha.\n",
            "Qual é o carro mais fora muito paradiso? Geraldo Álcool-Em-Mim.\n",
            "Qual a carro conta tudo? Nome.\n",
            "Por que os cães da Austrália ficam roucos? Porque a capital do país se chama cão-berra.\n",
            "Por que os papéis e as folhos gostam de casas de razão? Porque eles folhos razão.\n",
            "Qual a parte mais do mundo mais gosta de flores? Assassins Farm.\n",
            "Qual é o eletrodoméstico do vulcão? Domestique Vim-Pool.\n",
            "Qual o perguntou se ele gostava da Griswá? Pablo Salva-z-Ui-Ceno.\n",
            "Qual é o frango que está sempre na mesa? O frango alinamesa.\n",
            "Qual é a profissão do Thor? CorreThor.\n",
            "O que o Thor mais gosta de flores? Carlos Alber-thor (Carlos Alberto)\n",
            "Qual é a parte mais do jogo que os 4 filhas? Jogo de flores.\n",
            "O que é um grande entre aranha e um preguiçoso? É um grande entre au-taco.\n",
            "Qual é o hanna que mais gosta de flores? Carlos Alber-thor (Carlos Alberto)\n",
            "Por que estava batendo a capital do Equador? Porque era um capital do 3-D-itation.\n",
            "Qual é o fenômeno que acontece no mar que o Thor tem medo? Thormenta.\n",
            "Qual é o animal que mais gosta de flores? Carlos Alber-thor (Carlos Alberto)\n",
            "Qual é a profissão do Thor? CorreThor.\n",
            "Qual é o animal que gosta de flores? Carlos Alber-thor (Carlos Alberto)\n",
            "Eu tenho um cavalheiro que o Thor tem eu fim? His-THOR-e-i-kara.\n",
            "Qual o doce favorito do Thor? Thortuguita.\n",
            "Por que um 10ago no tudo? Porque ele não tenho um ladhor tudo.\n",
            "O que o zero dise para o oito? Nossa.\n",
            "O que o zero dise para foi fazer no espaço? Foi cantar pá god (Pagode)\n",
            "Qual é o estado preferido do Thor? THORude.\n",
            "Qual a semelhança entre aranha e escorpião? Com nenhum dos dois dá pra fazer bolo de abacate.\n",
            "Meu avô tem 4 filhas, cada filho tem 4 filhas. Quantos primos eu tenho? 12. Três são meus irmãos e um sou eu.\n",
            "Eu tenho do eu sou? Eu gasem têth.\n",
            "Eu tenho do germário? Eu tigre.\n",
            "Eu tenho dos mejores? Eu tigre-grafia.\n",
            "Eu tenho dente de bicicleta? Eu teclado.\n",
            "Eu tenho lobo de tomar chá? Eu teclado.\n",
            "Eu fimososo eu revocar também mantórez? Nu hochardende.\n",
            "Por que o Batman mais gosta de fazer? Porque ele é paciente.\n",
            "Qual é o time mais regal-doce? Tony.\n",
            "Qual é a group habitão que o Thor tem medo? Thormenta.\n",
            "Represento o\n",
            "\n",
            "[610 | 2719.45] loss=0.02 avg=0.22\n",
            "[620 | 2762.92] loss=0.03 avg=0.21\n",
            "[630 | 2806.39] loss=0.02 avg=0.21\n",
            "[640 | 2849.86] loss=0.02 avg=0.20\n",
            "[650 | 2893.33] loss=0.02 avg=0.20\n",
            "[660 | 2936.80] loss=0.02 avg=0.20\n",
            "[670 | 2980.26] loss=0.02 avg=0.19\n",
            "[680 | 3023.71] loss=0.02 avg=0.19\n",
            "[690 | 3067.14] loss=0.02 avg=0.19\n",
            "[700 | 3110.59] loss=0.01 avg=0.18\n",
            "[710 | 3154.02] loss=0.02 avg=0.18\n",
            "[720 | 3197.43] loss=0.02 avg=0.18\n",
            "[730 | 3240.90] loss=0.01 avg=0.17\n",
            "[740 | 3284.32] loss=0.01 avg=0.17\n",
            "[750 | 3327.74] loss=0.02 avg=0.17\n",
            "[760 | 3371.21] loss=0.02 avg=0.16\n",
            "[770 | 3414.66] loss=0.02 avg=0.16\n",
            "[780 | 3458.10] loss=0.02 avg=0.16\n",
            "[790 | 3501.56] loss=0.02 avg=0.16\n",
            "[800 | 3545.02] loss=0.02 avg=0.15\n",
            "======== SAMPLE 1 ========\n",
            "raado.\n",
            "O que o milho disse para a pipoca? HuMILHO mesmo.\n",
            "Qual é o doce preferido do Thor? Thorrone.\n",
            "Qual é o prato preferido do Thor? Thorresmo.\n",
            "O que o Thor faz quando corta o dedo? Thorniquete.\n",
            "O que acontece se o Thor assoprar? THORnado.\n",
            "Quantas pata tem uma pata? Somente uma, se fosse mais seria patapatapatapata...\n",
            "Qual é a semelhança entre aranha e escorpião? Com nenhum dos dois dá pra fazer bolo de abacate.\n",
            "Meu avô tem 4 filhos, cada filho tem 4 filhos. Quantos primos eu tenho? 12. Três são meus irmãos e um sou eu.\n",
            "Ela tinha 4 filhos. Janeiro, Fevereiro, Março. Qual é o nome do quarto filho. O nome da criança e 'Qual'.\n",
            "Qual o esporte que os cientistas gostam? Fórmula 1.\n",
            "Qual a profissão histórica do Thor? His-THOR-iógrafo.\n",
            "Qual a catástrofe que o Thor tem medo? TerremoTHOR.\n",
            "O que o gato faz quando está na rua? Engata.\n",
            "Qual é a profissão do Thor? Mo-THOR-iz-oca.\n",
            "Qual a especialização do Thor? PaTHORlogia.\n",
            "Qual a profissão secreta do Thor? InspeThor.\n",
            "Qual é o frango que está sempre na mesa? O frango alinamesa.\n",
            "Qual é a profissão do Thor? Thoreiro.\n",
            "Qual o pão que o Thor mais come? O THORrado.\n",
            "No carro estavam 1 avó, 2 pais, 2 filhos e 1 neto. Quantas pessoas estavam no carro? 3 pessoas.\n",
            "O que é surdo e mudo mas conta tudo? Livro.\n",
            "Por que a fração não cabe em uma casa? Por que ela tem 4 quarto.\n",
            "Qual a parte do corpo que Thor mais gosta? Thornozelo.\n",
            "O que o zero disse para o seis? Nossa, apertou tanto o cinto que abriu a boca.\n",
            "Qual e o animal que mais gosta de jogar futebol? GOLfinho.\n",
            "Qual é o carro que só anda bem vestido? Blazer.\n",
            "Por que guarda de trânsito é o ser mais forte do mundo? Porque ele pode parar carros só com uma das mãos.\n",
            "Qual é o fenômeno que acontece no mar que o Thor tem medo? Thormenta.\n",
            "Qual é o animal que mais gosta de jogar futebol? O goooooooooolfinho.\n",
            "Tinha um pontinho verde no Xbox, qual é o nome do jogo? Assassins GreenD.\n",
            "Por que não podemos levar cães pros Estados Unidos? Porque lá fura-cão.\n",
            "Qual é o país feminino? VenezuELA.\n",
            "Qual a meditação que se faz acordado? ONnnn...\n",
            "O que a legume é do filho do filho dela? Avóbora.\n",
            "O que o zero dise para o oito? Nossa, que cinto apertado!\n",
            "O que passa por todas as casas mas não sai do lugar? A rua.\n",
            "Cinco políticos estavam em uma lancha que acabou virando no meio do mar. Você sabe como salvá-los? Não? Perfeito!\n",
            "Qual é o bicho que anda com as patas? O pato.\n",
            "O que o Thor gosta de ser no tempo livre? Fo-THOR-grafo.\n",
            "Por que as mulheres não sentem frio? Porque elas estão cobertas de razão.\n",
            "Por que em Minas Gerais não tem mar? Porque lá eles rezam livrai-nos de todos os mar.\n",
            "Qual o animal que a\n",
            "\n",
            "[810 | 3607.22] loss=0.02 avg=0.15\n",
            "[820 | 3650.66] loss=0.01 avg=0.15\n",
            "[830 | 3694.09] loss=0.01 avg=0.15\n",
            "[840 | 3737.51] loss=0.02 avg=0.14\n",
            "[850 | 3780.97] loss=0.02 avg=0.14\n",
            "[860 | 3824.42] loss=0.01 avg=0.14\n",
            "[870 | 3867.84] loss=0.01 avg=0.14\n",
            "[880 | 3911.27] loss=0.02 avg=0.14\n",
            "[890 | 3954.69] loss=0.01 avg=0.13\n",
            "[900 | 3998.11] loss=0.01 avg=0.13\n",
            "[910 | 4041.50] loss=0.02 avg=0.13\n",
            "[920 | 4084.99] loss=0.02 avg=0.13\n",
            "[930 | 4128.44] loss=0.01 avg=0.13\n",
            "[940 | 4171.86] loss=0.01 avg=0.12\n",
            "[950 | 4215.31] loss=0.02 avg=0.12\n",
            "[960 | 4258.72] loss=0.02 avg=0.12\n",
            "[970 | 4302.15] loss=0.02 avg=0.12\n",
            "[980 | 4345.57] loss=0.02 avg=0.12\n",
            "[990 | 4388.96] loss=0.02 avg=0.12\n",
            "[1000 | 4432.35] loss=0.01 avg=0.11\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6965eb-bfa8-44ef-c32c-f3dcb4155e20"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824c86c4-ade3-460e-d15c-c4e03d97da03"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qual é a comida mais devagar? A devagarço.\n",
            "O que acontece se o coqueiro beber demais? Ele leva o burro e de um cachorro.\n",
            "Qual o ator que livra as pessoas das dores? Malvino Salva-dor.\n",
            "Por que as vogais A, E, I e O foram rejeitadas pela banda Scorpions? Porque eles Still Love U.\n",
            "Qual a atriz mais enxuta? Deborah Secco.\n",
            "Qual o santo do Rodrigo? São Toro.\n",
            "Qual enfermidade tem o técnico da seleção brasileira de futebol quando entra em um labirinto? Labirin-Tite.\n",
            "Qual o jogador que só vive com raiva? Bravo.\n",
            "O que todo homem faz quando está no banheiro? Sai do banheiro.\n",
            "Por que o nadador jogou a televisão na piscina? Para fazer um nado sintonizado.\n",
            "Por que o italiano tem que se equilibrar jogando xadrez? Porque senão ele perde sua torre.\n",
            "Por que a cama do sabão facilmente estoura? Porque seu colchão é de espuma.\n",
            "Qual é o eletrodoméstico preferido do Batman? Bat-deira.\n",
            "Qual comida que quase tira um 10? Strogo-nove.\n",
            "Qual o brinquedo preferido do McDonald's? McSteel.\n",
            "O que a vaca foi fazer na papelaria? Comprar uma muuuuuuuu-chila.\n",
            "Qual o material escolar que mostra a parte de seu corpo que dói? Aponta-dor.\n",
            "Qual a rede social mais gorda? InstaGrama.\n",
            "Qual é o tipo de festa que os cegos frequentam? O braille funk.\n",
            "Por que no Rio de Janeiro as pessoas não comem pão de sal? Porque eles têm o Pão de Açúcar.\n",
            "Qual super herói tira foto no escuro? Flash.\n",
            "Quando está apaixonado, como um sabão em pó se declara? Eu te OMO.\n",
            "O que a mãe açaí disse para os outros açaís? O último açaí feche a porta.\n",
            "Qual é o carro que gosta de fazer exercícios? Cooper.\n",
            "Por que o pai do Thor é um ser pré-histórico? Porque ele é Odinossauro.\n",
            "O que o Batman faz com o celular? Bat-Selfie.\n",
            "Qual o contrário de futsal? Fut-açúcar.\n",
            "Como seria o nome chinês do preguiçoso? Kan-sei ou kochi-lin.\n",
            "Por que o relógio é popular? Porque ele é da hora.\n",
            "Por que a piada da bola é a melhor? Porque ela é bem bolada.\n",
            "Qual é o traficante que toma uma gelada no boteco? Pablo Skol Bar.\n",
            "O que tem 5 cordas e uma cova? Violão.\n",
            "Qual o santo da Ivete? São Galo.\n",
            "Qual é o chocolate dos gatos? Kit-Cat.\n",
            "Qual o esporte preferido dos gaúchos? Basquetchê.\n",
            "Quem é o rei da farmácia? Rei-médio.\n",
            "Qual o contrário de buscapé Levamão.\n",
            "Qual o carro mais amado da Julieta? Alfa-Romeu.\n",
            "Qual a cerveja preferida dos mineiros? Bud-Uai-Zé.\n",
            "Por que a Holanda não cresce? Porque ela é um País-Baixo.\n",
            "Qual o contrário de cachorro-quente? Cadela fria.\n",
            "Por que o frango atravessou a rua? Porque era dia de folga da galinha.\n",
            "Por que o Thor é rico? Porque ele tem O-din-din.\n",
            "O que é o quê é e branco não é líquido e serve pra bebê? Fralda.\n",
            "Qual é o veículo que\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"LORD\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "4e0c8a3f-3527-41c4-e3fe-3357f3f8f6c2"
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 354Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 131Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 279Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:23, 131Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 226Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 199Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 18:37:58.571830 139905369159552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The secret of life is that it's really easy to make it complicated,\" said Bill Nye, the host of the popular science show \"Bill Nye the Science Guy.\" \"And this is one of the reasons why we all need to be smarter about science, because we can't keep up with the amazing things that are going on all the time.\"\n",
            "\n",
            "While Nye is correct that \"everything that's going on all the time\" is making the world a better place, he misses the point. This is not\n",
            "====================\n",
            "The secret of life is in the rhythm of the universe. It's not a mystery. It's not a mystery to me. It's the nature of the universe. It's the beauty of the universe. It's the way the universe works. It's the way the universe is. It's the way the universe is going to work. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way\n",
            "====================\n",
            "The secret of life is in the universe.\n",
            "\n",
            "\n",
            "-\n",
            "\n",
            "The Red Devil\n",
            "\n",
            "It's the end of the world as we know it, and the only thing that can save us is a band of super-powered individuals known as the Red Devil.\n",
            "\n",
            "\n",
            "The Red Devil is a group of super-powered individuals who are seeking the secret of life and the only way they know how to do it is by taking on the roles of a variety of different super-powered individuals, each of which has their own\n",
            "====================\n",
            "The secret of life is in the mixing of the elements, and it is the mixing of the elements that makes life possible.\"\n",
            "\n",
            "But in the world of food science, the idea of a \"complex\" or \"complexity\" is almost entirely imaginary.\n",
            "\n",
            "As a scientist, I'm fascinated by the question of how life first began.\n",
            "\n",
            "It's the question that drives my work and the work of the scientists who work on it.\n",
            "\n",
            "My current research is exploring how microbes work in the first moments\n",
            "====================\n",
            "The secret of life is the journey of life, the search for the truth.\n",
            "\n",
            "4.4.2. The last thing you know\n",
            "\n",
            "There is nothing more important than the last thing you know.\n",
            "\n",
            "4.4.3. The little things that make all the difference\n",
            "\n",
            "The little things that make all the difference.\n",
            "\n",
            "4.4.4. The truth is the best teacher\n",
            "\n",
            "The truth is the best teacher.\n",
            "\n",
            "4.4.5. The truth is what\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}